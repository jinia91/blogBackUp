# 개요

- 회사에서 서비스중인 운영계 앱 로그인이 되지 않는 긴급 장애 상황(5.1, 9:41 GMT+9 ~ 10:41 GMT+9) 

## 현재 상황 (As-is)

| 감지 | 결과 |
| --- | --- |
| 최초 Sentry를 통해 Alert | `HikariPool-1 - Connection is not available, request timed out after ~~`<br> 응답이 오지 않는 상황, 타임 아웃 감지 |



## 원하는 결과(To-be)

> 정상적인 로그인이 되야함

## 원인 분석

### 앱 ~ 인프라 레이어에서 접속 시도

| 시도 | 결과 |
| --- | --- |
| 운영계 앱 | 불가능 |
| 운영계 Admin | 가능 |
| 앱 | 불가능 |
|DB reboot | 여전히 불가능 |
|Cloud 9 콘솔에서 시도 | 불가능 |
| rds상에서 모니터링 | 클러스터 - 인스턴스는 구동중 |

### 트러블 시나리오 추측

1. 어드민쪽은 접속이 되는걸로 미뤄보아, 어드민쪽 커넥션이 해제되지 않아 커넥션풀 기아(starvation) 상황?
    - aws rds 콘솔로 확인 결과 커넥션풀 문제는 없음
    - admin  /운영앱 재배포, rds 재배포후에도 장애 지속되므로 커넥션풀 문제는 아님

2. rds db인스턴스는 정상 구동중, 애플리케이션도 정상구동중, 연결의 문제?
    - **db 인스턴스의 엔드 포인트와 서버 db 연결 엔드포인트 주소 조회 결과 불일치 확인**


## 트러블 슈팅

- 앱의 db Url 변경후 긴급배포
- 정상 구동 확인 완료 트러블 슈팅 완료

## 원인?

현재 사내 DB 인프라는 AWS RDS Aurora Mysql을 클러스터로 사용하고 있으며, Read/Write가 가능한 원본 인스턴스와 Read Only Replica 두개의 인스턴스가 존재한다.

    <예시>
    example-db
    ㄴ example-write
    ㄴ example-read-only

이때 AWS RDS 에서 제공하는 엔드포인트는 2종류인데, 하나는 `example-write`, `example-read-only` 인스턴스 각각에 대한 엔드포인트 이며, 또다른 하나는 두 인스턴스의 엔드포인트를 클러스터로 추상화한 `example-db`차원에서의 엔드포인트이다.

### 개별 인스턴스의 엔드포인트 예시

    앱.xyzzyexample.us-east-1.rds.amazonaws.com # writer
    앱.xyzzyexample.us-east-1.rds.amazonaws.com # reader

### 추상화한 클러스터의 엔드포인트 예시

    prod-db.cluster-xyzzyexample.us-east-1.rds.amazonaws.com    # writer
    prod-db.cluster-ro-xyzzyexample.us-east-1.rds.amazonaws.com # reader



### 분석

현재 앱에서는 위의 두종류 엔드포인트중 개별 인스턴스의 엔드포인트를 바라보는 중이였는데, 놀랍게도 `writer` 와 `reader` 인스턴스 두개의 엔드포인트가 서로 스왑되었음을 확인하였다.

따라서 앱에서는 현재 Writer Url을 Reader로, Reader Url을 Writer로 바라보고 있었고, Admin 메인에서는 순수하게 GET 조회를 하므로 큰 문제가 없었으나,

로그인시에는 비즈니스로직상 DB를 업데이트하는 트랜잭션이 묶여있었고, Reader DB에 접근하므로 해당 쿼리를 날리지 못해 요청 오류가 터진것으로 분석되었다.

aws 공식 doc 와 구글링결과 클러스터 내의 인스턴스 엔드포인트가 변경되는일은 `정상적인 일은 아니며` 굉장히 드물게 발견되는 예외상황으로 파악된다.

그리고 이런 `모종의 이유로` 인스턴스 엔드 포인트의 변경이 되어 장애가 발생하는 상황을 피하기 위해서는 `추상화한 클러스터 엔드포인트를 바라보길 권장`하는 tip을 발견했다.

따라서 사내 앱도 해당 엔드포인트로 재변경하여 재배포를 진행하였다.

## 결론

사내 앱이 아직 파일럿단계였기에 망정이지, 정식 릴리즈하여 많은 사용자가 이용하고 있었다면 정말 초대형장애에 해당하는 트러블이였다.

여러 조사 결과 클러스터 내 인스턴스 엔드포인트가 변경되는일은 극히 드물게 보고되는 사례로 보이고, 공식 Doc를 읽고 최대한 이해해보면

모종의 이유(우리쪽 문제든, aws의 문제든)로  `원본 인스턴스의 일시적 장애 발생 -> replica 인스턴스가 원본으로 승격 -> 원본 인스턴스가 replica로 강등` 시나리오 정도로 추측된다.

다만 이런 사태를 원천적으로 피하기 위해 추상화된 클러스터 엔드포인트를 이용키로 했으므로 이슈가 재현될일은 없을것이다.

해당 트러블에 직면하면서 인프라 지식, 클라우드 네이티브 지식, 특히 우리가 사용하는 aws에 대해 너무 모르고 사용하고 있었다는게 드러났고, 해당 지식을 제대로 공부해야함을 느꼈다.

이참에 aws 자격증 취득을 5월 목표로 공부해봐야겠다.