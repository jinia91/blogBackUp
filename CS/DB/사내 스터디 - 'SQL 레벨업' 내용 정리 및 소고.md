# SQL 언어의 패러다임 이해

## Set-Oriented-Aspect

![첨부 이미지](https://jinia-img-bucket.s3.ap-northeast-2.amazonaws.com/ad02b31c-7faf-4717-b1c5-07c91be9303e.png)

* SQL은 구문 하나 하나가 Statement가 아닌 Expression
* 따라서 Expression의 조합을 통해 질의 안에 로직을 태울수 있음
* 또한 집합 지향 사고를 통해 질의의 반환을 2차원 테이블 구조로 반환 가능
* 집합지향 사고를 통해 반복적인 조회(for-each)를 없앨 수 있음

> 소결: 프로그래밍 언어가 분기와 반복으로 로직을 전개하는것에 반해, SQL은 집합지향 사고와 expression의 조합을 통해 이루어진다

## 만약 SQL을 Statement로 접근한다면... -> 절차 지향적 접근

* 절차지향적인 접근은 반복문과 분기를 필연적으로 동반하고, 이는 잦은 DB조회를 낳음
* SQL은 기본적으로 반복문이 존재하지 않음
    * PL/SQL을 통해서 구현은 가능
    * 하지만 이는 SQL의 근본적 패러다임을 벗어난 편법

> RDB를 처음 고안했던 Edgar F.Codd는 '관계 조작은 관계 전체를 모두 조작의 대상으로 삼는다. 이러한것의 목적은 반복을 제외하는 것이다. 최종 사용자의 생산성을 생각하면 이러한 조건을 만족해야 한다. 그래야만 응용프로그래머의 생산성에도 기여할 수이 있을 것이다.'

* RDB와 SQL은 태생에서부터 의도적으로 `반복문`을 배제한 언어이며, 대신에 집합적인 사고방식을 통해 해결

> SQL은 `집합에서 원하는 데이터를 조회하는` 것이지 절차적으로 데이터를 뽑아오는 개념이 아니다!

## 저자가 말하는 for-each 쿼리의 문제점

### 많은 오버헤드를 필연적으로 동반

* 애플리케이션이 DB에 접근할때 발생하는 오버헤드들
    1. SQL 구문을 네트워크로 전송
    2. 데이터베이스 연결
    3. SQL 구문 파싱
    4. SQL 구문의 실행계획 생성 또는 평가
    5. 결과집합을 네트워크로 전송

특히 3, 4번의 오버헤드는 필연적으로 발생하며 감소시키기도 매우 어려움

### DB차원에서 병렬 분산 처리가 힘들다

단순쿼리는 연산 자체가 워낙 가벼워서 리소스를 분산해 병렬적으로 처리하기도 애매함, 오히려 포크-조인에서 오버헤드가 더 크게 발생할 위험도 존재

### DB의 진화로 인한 혜택을 받기 힘듬

* 현대 데이터베이스의 성능향상 / 기술발전은 대규모 데이터를 다루는 복잡한 SQL구문을 빠르게 개선하는데 치중되어있음
* 따라서 작은 쿼리일수록 관심사에서 벗어나며, 성능 향상은 미비할수밖에 없다고 주장

## 만약 for-each 쿼리 속도를 개선하려면?

### 잘 튜닝된 한방쿼리로 재작성하여 오버헤드 제거

### 각각의 SQL 을 최대한 최적화

* 하지만 반복계 쿼리는 기본적으로 매우 단순하기때문에 성능최적화에 한계가 존재

### DB 다중화처리

* DB를 샤딩하여야 하는데 RDB에 적합한 문제 해결방법으로 보기 어려움

## for-each 반복쿼리의 장점

### 실행계획의 안전성

* 단순한 쿼리는 기본적으로 옵티마이저가 해석하기 쉽기때문에 실행계획이 안정적이며, 실행계획이 갑자기 바뀌는 리스크가 매우 낮음

### 트랜잭션 제어가 편리

* 단순한 쿼리는 트랜잭션 자체도 짧기 때문에 정밀도를 미세하게 제어하기 쉽고, 전체 로직을 다루기도 쉬움

## For-each 질의의 예시

> Union을 통해 살펴보기

### Union을 사용한 조건분기의 문제점

* Union은 기본적으로 여러 쿼리를 단순히 합쳐서 반환해주는 방식으로 동작
* 사실상 여러 쿼리를 날리는것과 동일

> 조건분기를 where구로 하느 사람은 초보자다. SQL을 잘 다루는 사람은 Select 구만으로 조건분기를 한다.

## Case 구문을 사용해서 조건 분기를 식으로 탑재하기

* Case 구문자체는 `분기처리`하는 로직을 담고 있음
* 분기처리된 결과 자체를 집합물(`2차원 테이블`)로 반환받음으로서 잦은 I/O 조회(`여러 쿼리를 for문으로 날리기`)에서 벗아날 수 있음
* SQL을 구문(`Sentence`)이 아닌 식(`Expression`)으로 사고한 결과

## 소결

* 많은 쿼리 == 잦은 I/O는 많은 오버헤드를 낳고, 이러한 오버헤드는 성능 저하를 야기
* 되도록 I/O 접근 빈도를 줄이는 것이 성능 개선의 key
* 이를 위해서는 SQL 을 구문이 아닌 식(`expression`)으로 바라보는 관점이 중요
* SQL을 식(`expression`)으로 사고하면 SQL로 반환받는 데이터를 집합적인 관점으로 바라볼 수 있게 됨

## 하지만 현대 애플리케이션에서 DB중심 설계는?

* 현대 어플리케이션 트렌드는 데이터 중심 설계에서 벗어나 비즈니스 로직을 최대한 서버단에서 처리하고, DB는 저수준의 CRUD 정도로만 사용하려함
* Set-Oriented-Aspect 는 성능을 위해 반복문, 조건분기를 DB단으로 자연스럽게 끌고오게되며, 데이터 중심의설계를 유도할수밖에 없다.

### 웹서버와 DB서버의 scaleability 차이

* 웹서버는 scale-up, out 모두 용이한편
* 하지만 RDB의 경우 기본적으로 scale-up만 가능하고, scale-out은 복잡도와 비용이 매우 높고, scale-up 자체의한계도 존재(선형적으로 비용이 증가하지 않음)

### 유지보수 관점

* 집합적인 사고 자체가 직관적이라고 말하기 어려우며, 가독성이 좋다고 말하기도 힘듬
* 데이터 중심의 애플리케이션 설계는 애플리케이션의 아키텍처가 영속성계층에 지나치게 종속되는 결과를 만들고, 유지보수를 어렵게 만듬

### 성능 - 설계 트레이드오프

* 로직을 애플리케이션단으로 끌고오면, 아무래도 최적의 쿼리를 작성하기엔 어려워지고, 필연적으로 db단 조회는 증가, 더 많은 오버헤드를 만들수밖에 없음
* 하지만 짧은 트랜잭션을 통한 안전성, 유지보수의 편의를 생각하면 현대 애플리케이션의 설계는 비즈니스 로직을 서버단에서 하는것이 더 낫다 판단됨

## 소결

* 집합적 사고와 선언형 언어의 이해를 바탕으로 저수준의 sql 최적화는 여전히 필요하다고 생각
* 하지만 책에서처럼 쿼리중심으로 어플리케이션을 설계하고, 비즈니스 로직을 DB단으로 끌어내리는 방식은 현재 트렌드와는 거리가 있다.
* 성능과 유지보수, 트레이드 오프를 잘 고려하자


# 기능적 관점으로 Join 분류

## 크로스 조인(cross join)

* 모든 결합의 모체
* N \* M 의 카티션 곱을 그대로 출력
* 하지만 실무에서 사용할일은 적음
    * 왜냐면 크로스 조인을 하는 데이터가 필요할 일이 거의 없기 때문
* 카티션곱의 조인을 실수로 사용하지 않기 이해서라도, `on`을 사용해 inner join을 하기를 추천

## 이너 조인(inner join)

* 카티션 곱의 부분집합
* 카티션곱으로 만들어진 테이블에서 `on` 조건에 충족되는 데이터만 출력한것이라고 보면됨

## 아우터 조인(outer join)

* `outer`인 이유는 카티션 곱의 외부데이터가 들어갈 수 있기 때문!
* 마스터가 되는 테이블의 모든 정보를 보존하고자 null을 생성하기 때문에 카티션 곱 이외의 데이터도 존재하게 된다.

# Join 알고리즘과 성능

* Nested Loops
* Hash
* Sort Merge

> mysql은 8.0 이상 버전부터 join시 Hash 알고리즘 사용가능, aws aurora DB도 최신버전은 Hint구문을 사용하면 가능하다고함

## Nested Loops

* 사실상 2중 for 문
* 구동테이블(outer table)을 기준으로 내부테이블(inner table)에 순차적으로 접근하며 2중 for문을돌고 조건에 맞는 데이터를 join하는 방식
* 가장 일반적인 join 알고리즘

### Nested Loops 성능 개선 - Inner Table Index!

* 데이터 큰테이블을 inner table로 잡을것!
* outer 테이블은 필연적으로 모두 접근해야하므로,Full table scan을 피할수 없으나, inner table은 조건에 맞는 데이터를 탐색하므로 **결합키에 index가 걸려있으면** index 활용이 가능하다.
* 따라서 데이터가 큰 테이블을 Inner table로 삼고 index를 잘 사용하면 극적인 성능 향상을 달성할 수 있음

### 성능 개선이 힘든 상황

> 결합키의 유일성이 보장되지 않아, 인덱스 탐색시 중복히트가 너무 많이 발생하는 경우

* 이때는 만약 데이터가 적은 테이블(`현재 구동테이블`)의 결합키가 유일성을 보장한다면, 역설적으로 데이터가 적은 테이블을 inner table로 바꿔보는것도 좋은 시도
* Hash Join 사용하기

## Hash

* mysql 8 이상부터 지원
* 데이터가 작은 테이블을 기준으로 결합키를 사용해 메모리상의 해시테이블을 만들고, 큰 데이터 테이블을 순회하며 결합키에 해당하는 해시테이블에 선형접근(O(N))하여 join 시키는 알고리즘
* 메모리에 해시테이블을 만들어야 하므로, 메모리가 부족하면 디스크를 사용하는 페이징이 일어나고(`temp`) 지연발생
* 해시값은 순서를 알지는 못하므로, 등치 결합(`on(a.~~=b.~~)`)에만 사용 가능
* nest loops 알고리즘사용시 inner table에서 히트되는 레코드 수가 너무많거나 인덱스가 존재하지 않을때 좋은 대안이 된다.

## Sort-Merge

* mysql은 지원 x
* join 할 양 테이블을 각각 메모리상에 띄워 결합키를 기준으로 정렬하고, 매칭되는 결합키에 맞게 join시키는 방식
* 정렬을 통해 join하므로, 부등호 결합에도 사용가능하며, 테이블이 결합키로 정렬되있다면, 정렬 생략이 가능

## 소결

| 이름 | 장점 | 단점 |
| --- | --- | --- |
| Nested Loops | \- 작은 구동 테이블 \+ 인덱스 내부테이블시 성능이 좋고 제약이 적음 | 대규모테이블끼리의 join시엔 부적합하고 인덱스가 없으면 비효율적 |
| Hash | 대규모 테이블간 결합시 유용 | 메모리 소비량이 큼, 등가 결합밖에 안됨 |
| Sort Merge | 대규모 테이블간 결합시 유용 | 메모리 소비량이 매우 큼 |

* 기본적으로는 Inner table 결합키에 Index를 건 Nested Loops, 잘 안되면 Hash

# 서브 쿼리

## 서브 쿼리의 문제점

### 연산 비용

* 임시테이블을 만들고 그 테이블을 조회하는 방식이므로 매 쿼리마다 연산비용이 추가

### 데이터 I/O 발생

* 위의 이유로 사실상 추가적인 쿼리를 더 날리는셈이고 I/O가 일어남

### 최적화가 불가능

* 대표적으로 인덱스를 걸수 없기 때문에, 최적화가 불가능

## 해결책

### 윈도우 함수 사용

> 기존의 RDBMS는 칼럼과 칼럼의 연산은 쉬운 반면 행과 행의 관계를 연산하거나 정의하는 일은 굉장히 어려운 문제였다. 따라서 이러한 문제를 쉽게 해결할 수 있도록 제시된 것이 WINDOW FUNCTION이다.

* 튜플간의 연산을 쉽게 해주는 함수로 윈도우 함수를 이용하면 순위, 합계, 평균, 행 위치 등을 조작할 수 있다.
* mysql 8버전 이상부터 지원

### 서브쿼리가 더 나은 경우도 존재한다

* join과 집계함수를 동시에 써야하는 상황에서 Join 연산을 줄이기 위해 선 집계후 해당 집계 테이블을 서브쿼리로 Join하는 상황

# 레코드에 순서 붙이기

## 단순 id 정렬시

### 윈도우 함수 사용

* row\_number()

### 상관 서브쿼리(select 서브쿼리)사용

> select id, (select count(\*) from table t2 where t2.id <= t1.id) from table t1

## 다중키로 정렬시

### 윈도우 함수 사용

* row\_number() over(column1, column2)

### 상관 서브쿼리 사용

> select column1, column2, (select count(\*) from table 
> t2 where (t1.column1, t2.column2) 
> <= (t1.column2, t2.column2)) from table t1

## 그룹마다 순번붙이는 경우

### 윈도우 함수 사용

* row\_number() over (partition by column1 order By column2)

### 상관 서브쿼리 사용

> select column1, cloumn2, (select count(\*) from table t2 where t1.column1 = t2.column2 
> and t1.column2 <= t2.column2) from table t1

## generate Id 전략

* Sequence
* Identity
* table

### Sequence

* DB 스키마 내부에 존재하는 Sequence객체를 사용(view, table 등과 동등한 객체)
* mysql은 사용 불가능
* `nextVal`사용
* 성능상 문제가 존재

#### 성능상 문제점

* 유일성, 연속성, 순서성을 만족시키기 위해 Beta Lock을 사용
* 따라서 동시에 여러 사용자가 시퀸스 객체에 접근하는 경우 락 충돌로 인해 성능 저하 문제가 발생
* 시퀸스 객체가 저장된 디스크에 잦은 조회가 일어나는데, 이때 hot spot 이슈가 발생
* jpa로 구현시 시퀸스로부터 id를 가져오기위해 네트워크를 추가로 타는 이슈 존재

#### 성능 문제 해결법

* cache로 미리 채번
* `noorder`옵션으로 순서성 담보를 포기하고 성능 향상

### Identity 필드

* id 값을 null로 하면 DB가 알아서 AUTO\_INCREMENT
* 자동 순번 필드라고도 불리우며, 테이블마다 개별적으로 종속되어 작동함
* 성능적으로는 sequence객체보다도 비효율적
    * 튜닝방식도 존재하지 않음
    * jpa상에서 bulk insert 사용 불가능(`1만튜플 insert 기준 성능은 약 2배정도 차이`)

### table 방식

* 시퀸스 객체가 아닌 시퀸스 테이블을 통해 시퀸스 객체의 메커니즘을 흉내내는방식
* 시퀸스 객체에 비해 최적화된 방식이 아닌 흉내내는방식이므로 성능상 문제가 있음
* 실제 프로덕트 레벨에서는 추천되지 않음



# 시야 협착 회피하기
>  망치라는 도구만을 가진 사람에게는 모든 문제가 못으로 보인다.<br>
> \- Abraham Harold Maslow

## 시나리오
     1. 주문 테이블이 존재하며, 주문테이블의 컬럼에는 주문 생성날짜, 배송 도착 예정 날짜가 존재.
     2. 주문이 생성될 때, 주문 생성날짜와 배송 도착 예정 날짜가 레코드로 삽입
     
     3. 배송 도착 예정 날짜는 수시로 변경될 수 있음
     
     4. 요구사항 : 배송 도착 예정날짜 - 주문 생성날짜의 값이 3일 이상일경우 배송이 늦어진다는 표시
    

## SQL 을 통한 해결책

간단한 요구사항이므로 모든 주문에 대해 `배송 도착 날짜 - 주문 생성날짜`가 포함된 쿼리를 날리면 된다.

> select order_id, delivery_date - order_date as diff_days <br>
> from order <br>
> where delivery_date - order_date >=3;

## 시나리오 + 문제상황

    전제 조건 : 현재 데이터가 1억개 존재하고, 애플리케이션의 daily page view가 1억
    
    추가 요구사항 : 전체 주문에대한 지연상황을 실시간으로 메인화면에 띄워야함
    
    
    
위의 전제 조건과 추가 요구사항을 고려하면 1억건 데이터를 가진 테이블 전체를 하루에 1억번 sql을 통해 연산을 하며 데이터 조회를 해야한다.

이런 시나리오에서 sql 조회만을 통한 해결책보다 효율적인 방식은 없을까?

## 테이블 변경 + 배치를 통한 해결

단순히 order 테이블에 status 컬럼을 추가하고, 해당 컬럼에 delivery_delay 라는 레코드를 집어넣을수 있다고 생각해보자.

최초 데이터 insert시 지연에대한 정보를 넣어주기때문에, 조회시 연산을 빼고 배송이 지연되는 데이터만 조회가능하므로 보다 나은 조회가 가능하다.

문제는 시나리오상의 `배송 지연 날짜는 수시로 변경될 수 있음` 인데, 

이부분은 배치작업을 통해 일정 시간마다 변경 데이터를 갱신해줌으로서 실시간성에 대해 일정부분 포기하고, 성능을 챙기는 트레이드 오프 지점이다.

따라서 업무의 요구사항, 기획에 따라 적절히 판단하자.

## 핵심은 넓은 시야

위의 시나리오에서 sql을 통한 솔루션과 테이블 변경 + 배치작업을 통한 솔루션 둘다 이상적인 해결책은 아니다.

둘 사이에는 실시간성과 성능의 트레이드오프가 존재하고 이부분은 문제의 세부 요구사항에 따라 얼마든지 달라질 수 있다.

여기서 핵심은 문제상황을 맞닿뜨렸을 때, 익숙한 사용도구만을 가지고 해결하려는 `시야 협착` 에 빠지지말고 다양한 관점에서 접근하라는 것!

# Index

[인덱스 기본 개념](https://www.jiniaslog.co.kr/article/view?articleId=505)

## 인덱스를 잘 활용하려면

인덱스를 쓰면 마법처럼 성능이 개선된다고 믿지 말라

> No Silver Bullet - Essence and Accident in Software Engineering
> - 프레드 브록스 , 맨먼스 미신

### 카디널리티와 선택률

1. 카디널리티(cardinality)
    필드에 들어있는 값의 갯수. 카디널리티가 가장 높다면 모든 레코드에 다른 값이 들어있는 UK라는 뜻이며, 카디널리티가 가장 낮다면 모든 레코드에 동일 값이 들어있다는 의미
2. 선택률
    필드에서 특정 값을 조회할때, 테이블 전체에서 몇개의 레코드가 선택되는지를 나타내는 개념

### 인덱스가 Full table scan보다 더 빠를 기준?

>카디널리티가 높고, 선택률이 낮아야한다.

구체적 역치는 선택률이 10% 미만일때가 이상적

만약 10% 이상이라면 full table scan이 더 나은 선택일 수 있다.

## 인덱스를 사용하기 어려운 상황

### 1. 압축 조건이 없는 경우

    select id, name from table

반드시 모든 테이블을 조회해야하는 상황이므로, 어쩔수가 없다.

### 2. 레코드 압축이 어려운 경우

(1) 선택률이 높은상황

    select * from order where status = delivery
    
위의 상황에서 order테이블의 80%가 delivery 상태라고 가정해보면 status에 인덱스를 생성하는것은 오히려 성능 하락을 가져올 수 있다.

만약 delivery 상황이 매번 변동하여 어떤날은 5% 미만, 어떤날은 80%와 같이 변동될 경우 옵티마이저가 선택률이 낮은날엔 인덱스를 사용하면 이상적이나 이렇게 작동하길 기대하긴 어렵다.

### 3. 인덱스 사용 불가능 쿼리

- `like %string`
- `like %string%` 
- 인덱스 컬럼에 연산이 들어간경우
    - index_column * 1.1 > 100
    - length(index_column) = 10
- 부정형을 사용하는 경우
    - index_column <> 100


## 인덱스 사용이 어려울때 해결법

### 1. 비정규화

> 필요로 하는 데이터만을 따로 인덱스가 가능한 비정규화 테이블로 생성하고 해당 테이블을 조회하는 방식

단점

- 데이터 동기화 문제
    원본 데이터를 복사하여 비정규화 테이블을 새로 생성하고 갱신해야하는 만큼, 갱신 부하 부담과 갱신 빈도에대해 고려해야한다.
- 비정규화 테이블 크기
    해당 방식은 필요로 하는 데이터만큼 테이블을 줄여 I/O 부담을 줄이고 인덱스가 가능하게끔 하는것이 목적이므로 만약 필요로하는 데이터가 너무 크다면 큰 의미가 없다.
- 관리포인트 증가
    중복 테이블이 증가하는셈이므로 관리포인트가 증가하고 유지보수가 어려워진다

### 2. 인덱스 온리 스캔
> 조회 조건 전체를 커버할수 있는 다중 컬럼 인덱스를 만드는 방식

인덱스에 대한 조회는 full index scan이 아닌 이상 b+tree 자료구조를 사용해 데이터 접근을 하므로, 일반적인 table scan에 비해 훨씬 빠르다.

따라서 인덱스 자체에 조회에 필요한 모든 데이터 컬럼을 포함시키고 인덱스 서치를 통해서만 조회하게끔 하면 성능 향상을 이룰 수 있다.


단점

- 한개의 인덱스에 포함할 수 있는 필드수 제한(길이 제한)이 존재
- 갱신 오버헤드 증가
- 정기적인 인덱스 리빌드가 필요(유지관리해야함)
- 새로운 필드가 추가될경우 사용불가

 

# References

- [sql 레벨업](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9788968482519&orderClick=LEa&Kc=)